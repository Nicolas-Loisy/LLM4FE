# LLM4FE

### **1. Objectif du projet**

DÃ©velopper un **pipeline automatisÃ©** de **Feature Engineering (FE)**, **AutoML**, et **Benchmarking**, orchestrÃ© par un **Orchestrateur central**.  
Le projet doit permettre de **transformer dynamiquement un dataset** en utilisant un **LLM** qui gÃ©nÃ¨re un JSON de transformations via **response format / structured output**, puis d'entraÃ®ner un modÃ¨le AutoML et de benchmarker ses performances, en stockant les rÃ©sultats dans une structure versionnÃ©e.

---

## **2. Structure du projet**

Le projet suit une structure modulaire et organisÃ©e :

```
/LLM4FE
â”‚
â”œâ”€â”€ ğŸ“‚ data/  # Contient les datasets et modÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ models/  # Sauvegarde des modÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ logs/  # Fichiers de log de l'exÃ©cution du pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ orchestrator/  # Module central de gestion du pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ orchestrator.py  # Coordination du pipeline
â”‚   â”‚   â”œâ”€â”€ config.py  # Gestion des configurations
â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ feature_engineering/  # Module de transformation des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ fe_pipeline.py  # ExÃ©cution des transformations
â”‚   â”‚   â”œâ”€â”€ fe_factory.py  # Factory pour gÃ©rer dynamiquement les transformations
â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ transformations/  # Dossier contenant les transformations spÃ©cifiques
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base_transform.py  # Classe parent pour toutes les transformations
â”‚   â”‚   â”‚   â”œâ”€â”€ scaling.py  # Transformations de mise Ã  l'Ã©chelle
â”‚   â”‚   â”‚   â”œâ”€â”€ encoding.py  # Encodage des variables catÃ©gorielles
â”‚   â”‚   â”‚   â”œâ”€â”€ text_processing.py  # Traitement du texte (TF-IDF, embeddings, etc.)
â”‚   â”‚   â”‚   â”œâ”€â”€ math_operations.py  # Fonctions mathÃ©matiques (log, moyenne, etc.)
â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ llm/  # Gestion des appels au LLM
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_factory.py  # Factory pour supporter plusieurs modÃ¨les LLM
â”‚   â”‚   â”œâ”€â”€ openwebui_client.py  # Client pour lâ€™API OpenWebUI
â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ automl/  # EntraÃ®nement des modÃ¨les
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ automl_pipeline.py  # ExÃ©cution du processus AutoML
â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ benchmark/  # Ã‰valuation des modÃ¨les
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ benchmark.py  # Calcul des scores des modÃ¨les
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ run_pipeline.py  # Script principal lanÃ§ant le pipeline
```

---

## **3. Description dÃ©taillÃ©e des modules et interactions**

### **3.1. Orchestrateur (`src/orchestrator/`)**

L'Orchestrateur **coordonne les interactions entre les modules** et gÃ¨re les versions des datasets et modÃ¨les.

#### **ResponsabilitÃ©s :**

- **Charger les fichiers dâ€™entrÃ©e** (`dataset.csv`, `config.json`, etc.).
- **GÃ©rer les itÃ©rations et versions** :
  - GÃ©nÃ©rer `version_1`, `version_2`, etc.
  - Sauvegarder chaque version sous `/data/models/version_X/`
- **Appeler le module Feature Engineering** et rÃ©cupÃ©rer le **dataset transformÃ©**.
- **Appeler le module AutoML** et rÃ©cupÃ©rer le **modÃ¨le entraÃ®nÃ©**.
- **Appeler le module Benchmarking** et rÃ©cupÃ©rer les **scores du modÃ¨le**.
- **SÃ©lectionner la meilleure version** en comparant les scores.

---

### **3.2. Feature Engineering (`src/feature_engineering/`)**

Le module FE applique les transformations sur le dataset en **appelant un LLM** via l'API OpenWebUI.

#### **ResponsabilitÃ©s :**

- **GÃ©nÃ©rer un JSON structurÃ©** via un **appel LLM** utilisant un **response format / structured output**.
- **Appliquer dynamiquement** les transformations via un **FE Factory**.
- **Sauvegarder le dataset transformÃ©** (`Dataset_FE_vX.csv`).

#### **Appel au LLM avec response format**

Le JSON gÃ©nÃ©rÃ© par le LLM suit cette **structure stricte** :

```python
from pydantic import BaseModel
from typing import List, Optional, Literal

class Transformation(BaseModel):
    finalCol: str
    colToProcess: List[str]
    providerTransform: Literal['math', 'aggregation', 'encoding', 'scaling', 'custom']
    param: Optional[str]

class DatasetStructure(BaseModel):
    datasetStructure: List[Transformation]
```

#### **Exemple dâ€™appel au LLM :**

```python
import requests
import json

url = "https://openwebui.example/api/chat/completions"
api_key = "API_KEY"

headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {api_key}"
}

prompt = "GÃ©nÃ¨re des transformations adaptÃ©es Ã  ce dataset..."

data = {
    "model": "llama3.3:latest",
    "messages": [{"role": "user", "content": prompt}],
    "format": DatasetStructure.model_json_schema()
}

response = requests.post(url, headers=headers, data=json.dumps(data))
transformations = response.json()
```

---

### **3.3. AutoML (`src/automl/`)**

Le module **entraÃ®ne automatiquement des modÃ¨les** en utilisant des bibliothÃ¨ques comme **Auto-sklearn** ou **TPOT**.

#### **ResponsabilitÃ©s :**

- Charger le dataset transformÃ© (`Dataset_FE_vX.csv`).
- SÃ©lectionner un algorithme (Random Forest, XGBoost, etc.).
- EntraÃ®ner le modÃ¨le.
- Sauvegarder le modÃ¨le (`model_vX.pkl`).

---

### **3.4. Benchmarking (`src/benchmark/`)**

Le module **Ã©value les performances** du modÃ¨le entraÃ®nÃ©.

#### **ResponsabilitÃ©s :**

- Charger le modÃ¨le (`model_vX.pkl`).
- Calculer les scores (`accuracy`, `F1-score`, `AUC`, etc.).
- Sauvegarder les scores (`Model_Scores_vX.json`).
- Comparer les scores des diffÃ©rentes versions.

---

## **4. Processus dâ€™itÃ©ration**

1ï¸ **Lâ€™Orchestrateur dÃ©marre lâ€™itÃ©ration 1** :

- Il envoie le dataset brut au **module FE**.

2ï¸ **Le module Feature Engineering** :

- GÃ©nÃ¨re un **JSON structurÃ©** avec un **LLM (response format)**.
- Applique les transformations et sauvegarde `Dataset_FE_v1.csv`.

3ï¸ **Le module AutoML** :

- Charge `Dataset_FE_v1.csv`.
- EntraÃ®ne un modÃ¨le et sauvegarde `model_v1.pkl`.

4ï¸ **Le module Benchmarking** :

- Ã‰value `model_v1.pkl` et sauvegarde `Model_Scores_v1.json`.

5ï¸ **Lâ€™Orchestrateur passe Ã  lâ€™itÃ©ration 2** :

- Il relance le **Feature Engineering** avec `Dataset_FE_v1.csv`.
- Le cycle recommence jusquâ€™Ã  obtenir `Dataset_FE_vN.csv`.

6ï¸ **SÃ©lection de la meilleure version** :

- Lâ€™Orchestrateur compare les scores et sÃ©lectionne le **meilleur modÃ¨le et dataset**.

---

## **5. Technologies utilisÃ©es**

- **Python**
- **OpenWebUI API** pour les appels LLM
- **Pydantic** pour valider les JSON de transformations
- **Scikit-learn, Auto-sklearn, TPOT** pour AutoML
- **Pandas, NumPy** pour la manipulation des donnÃ©es
